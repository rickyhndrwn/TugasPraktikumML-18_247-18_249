{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing_Skenario_Praktikum_Modul_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0TJHRCZi8a4"
      },
      "source": [
        "## Preprocessing - Skenario Praktikum Modul 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlIlTUkMi8Io"
      },
      "source": [
        "### Define Direktori Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRQVBIi3izMM"
      },
      "source": [
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIlPrQB_jLGN"
      },
      "source": [
        "base_dir = '/content/drive/MyDrive/Pembelajaran Mesin/Tugas Kelompok Praktikum/Dataset/chest_xray'\n",
        "\n",
        "splitted_dir = os.path.join(base_dir, 'splitted_data')\n",
        "\n",
        "train_dir = os.path.join(splitted_dir, 'train')\n",
        "norm_train_dir = os.path.join(train_dir, 'normal')\n",
        "pneu_train_dir = os.path.join(train_dir, 'pneumonia')\n",
        "\n",
        "val_dir = os.path.join(splitted_dir, 'val')\n",
        "norm_val_dir = os.path.join(val_dir, 'normal')\n",
        "pneu_val_dir = os.path.join(val_dir, 'pneumonia')\n",
        "\n",
        "test_dir = os.path.join(splitted_dir, 'test')\n",
        "norm_test_dir = os.path.join(test_dir, 'normal')\n",
        "pneu_test_dir = os.path.join(test_dir, 'pneumonia')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkZ3bStVjNNA",
        "outputId": "5701ede4-7943-43a4-db20-68d9de3b9bca"
      },
      "source": [
        "print(\"Total Training NORMAL:\", len(os.listdir(norm_train_dir)))\n",
        "print(\"Total Training PNEUMONIA:\", len(os.listdir(pneu_train_dir)))\n",
        "print('-'*30)\n",
        "print(\"Total validation NORMAL:\", len(os.listdir(norm_val_dir)))\n",
        "print(\"Total validation PNEUMONIA:\", len(os.listdir(pneu_val_dir)))\n",
        "print('-'*30)\n",
        "print(\"Total Testing NORMAL:\", len(os.listdir(norm_test_dir)))\n",
        "print(\"Total Testing PNEUMONIA:\", len(os.listdir(pneu_test_dir)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Training NORMAL: 1266\n",
            "Total Training PNEUMONIA: 3418\n",
            "------------------------------\n",
            "Total validation NORMAL: 300\n",
            "Total validation PNEUMONIA: 811\n",
            "------------------------------\n",
            "Total Testing NORMAL: 17\n",
            "Total Testing PNEUMONIA: 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXEL1pRvjR4r"
      },
      "source": [
        "### Periksa Ratio Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl22i7tijRb7",
        "outputId": "3a838213-05d6-445d-c1ee-038fa1e58812"
      },
      "source": [
        "train_data_count = len(os.listdir(norm_train_dir)) + len(os.listdir(pneu_train_dir))\n",
        "val_data_count = len(os.listdir(norm_val_dir)) + len(os.listdir(pneu_val_dir))\n",
        "test_data_count = len(os.listdir(norm_test_dir)) + len(os.listdir(pneu_test_dir))\n",
        "total_data_count = train_data_count + val_data_count + test_data_count\n",
        "    \n",
        "print(\"Persentase Pembagian Data:\")\n",
        "print(f\"\\ttrain = {train_data_count / total_data_count * 100:.0f} %\")\n",
        "print(f\"\\tval = {val_data_count / total_data_count * 100:.0f} %\")\n",
        "print(f\"\\ttest = {test_data_count / total_data_count * 100:.0f} %\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Persentase Pembagian Data:\n",
            "\ttrain = 80 %\n",
            "\tval = 19 %\n",
            "\ttest = 1 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcCugM2UjX2x"
      },
      "source": [
        "### Augmentasi\n",
        "menggunakan **imagedatagenerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGD_cGx3jXir"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjS3AtLkjan4",
        "outputId": "7e3e0d5d-7aad-45e4-8503-6d7ab31f8b55"
      },
      "source": [
        "# data augmentation\n",
        "new_size = (180,180)\n",
        "\n",
        "train_val_gen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range=30,\n",
        "                                   zoom_range=0.4,\n",
        "                                   vertical_flip=True,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "train_generator = train_val_gen.flow_from_directory(train_dir,\n",
        "                                  target_size=new_size,\n",
        "                                  shuffle=True,\n",
        "                                  class_mode='binary'\n",
        "                                  )\n",
        "\n",
        "val_generator = train_val_gen.flow_from_directory(val_dir,\n",
        "                                  target_size=new_size,\n",
        "                                  shuffle=True,\n",
        "                                  class_mode='binary'\n",
        "                                  )\n",
        "\n",
        "test_gen = ImageDataGenerator()\n",
        "\n",
        "test_generator = test_gen.flow_from_directory(test_dir,\n",
        "                                  target_size=new_size,\n",
        "                                  shuffle=False,\n",
        "                                  class_mode='binary'\n",
        "                                  )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4684 images belonging to 2 classes.\n",
            "Found 1111 images belonging to 2 classes.\n",
            "Found 61 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGtI2CwYjeSs"
      },
      "source": [
        "### Penentuan bobot kelas\n",
        "untuk mengatasi permasalahan pada imbalanced data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8DoW_rljeEy",
        "outputId": "bbac607b-9d76-4997-c671-ed985e78ee8c"
      },
      "source": [
        "norm_count = len(os.listdir(norm_train_dir)) + len(os.listdir(norm_val_dir)) + len(os.listdir(norm_test_dir))\n",
        "pneu_count = len(os.listdir(pneu_train_dir)) + len(os.listdir(pneu_val_dir)) + len(os.listdir(pneu_test_dir))\n",
        "\n",
        "print(f\"Jumlah Normal: {norm_count}\\nJumlah Pneoumonia: {pneu_count}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah Normal: 1583\n",
            "Jumlah Pneoumonia: 4273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e2ItpdRjhtl",
        "outputId": "3c7aded2-e133-4844-879e-4b5313208dfd"
      },
      "source": [
        "weight_for_0 = (1 / norm_count) * (train_data_count) / 2.0 \n",
        "weight_for_1 = (1 / pneu_count) * (train_data_count) / 2.0\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print(f\"Bobot kelas 0: {weight_for_0:.2f}\")\n",
        "print(f\"Bobot kelas 1: {weight_for_1:.2f}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bobot kelas 0: 1.48\n",
            "Bobot kelas 1: 0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a7z07bXjkPy"
      },
      "source": [
        "### Simpan hasil preps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO_FVldSjkC9"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyKPiYrmjn2M",
        "outputId": "3158bead-fb3e-4c0e-896c-99d904bf2f01"
      },
      "source": [
        "x_train = np.concatenate([train_generator.next()[0] for _ in range(train_generator.__len__())])\n",
        "y_train = np.concatenate([train_generator.next()[1] for _ in range(train_generator.__len__())])\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4684, 180, 180, 3)\n",
            "(4684,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMF9pruijp_y",
        "outputId": "465649a3-0895-47a1-fdba-2dbd52db2537"
      },
      "source": [
        "x_val = np.concatenate([val_generator.next()[0] for _ in range(val_generator.__len__())])\n",
        "y_val = np.concatenate([val_generator.next()[1] for _ in range(val_generator.__len__())])\n",
        "\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1111, 180, 180, 3)\n",
            "(1111,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYYtVlGyjrdu",
        "outputId": "598dfc6c-1b59-4e3c-cb42-c31d55d7c733"
      },
      "source": [
        "x_test = np.concatenate([test_generator.next()[0] for _ in range(test_generator.__len__())])\n",
        "y_test = np.concatenate([test_generator.next()[1] for _ in range(test_generator.__len__())])\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(61, 180, 180, 3)\n",
            "(61,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g99H1PdjtBo"
      },
      "source": [
        "import json\n",
        "\n",
        "target_dir = '/content/drive/MyDrive/Pembelajaran Mesin/Tugas Kelompok Praktikum/Skenario Praktikum/Modul 4/Preprocessing'\n",
        "\n",
        "preprocessed_data = [x_train, y_train, x_test, y_test, x_val, y_val]\n",
        "preprocessed_file_name = ['x_train', 'y_train', 'x_test', 'y_test', 'x_val', 'y_val']\n",
        "\n",
        "for i, file_name in enumerate(preprocessed_file_name):\n",
        "    np.save(target_dir + '/' + file_name + '.npy', preprocessed_data[i])\n",
        "\n",
        "class_weight_file = os.path.join(target_dir, 'class_weight.json')\n",
        "json.dump(class_weight, open(class_weight_file, 'w'))"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}